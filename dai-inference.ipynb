{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null\n!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"../input/omegaconf\")\nsys.path.insert(0, \"../input/weightedboxesfusion\")\n\nfrom ensemble_boxes import *\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom torch.utils.data import Dataset,DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\nfrom matplotlib import pyplot as plt\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchEval\nfrom effdet.efficientdet import HeadNet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Dataset and AUgmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_convert_transforms():\n    return A.Compose([\n        A.Resize(1024,1024,p=1)\n    ],bbox_params=A.BboxParams(\n            format='pascal_voc',\n            min_area=0, \n            min_visibility=0,\n            label_fields=['labels']\n        ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_ROOT_PATH = '../input/dhakaai-2020/dhaka.ai test/test'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, image_ids, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle_in = open('../input/encoderr/encoder.pickle','rb')\nle = pickle.load(pickle_in)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle_in.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.transform(['minivan'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Create Dataset and Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = DatasetRetriever(\n    image_ids=np.array([path.split('/')[-1][:-4] for path in glob(f'{DATA_ROOT_PATH}/*.jpg')]),\n    transforms=get_valid_transforms()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loader = DataLoader(\n    dataset,\n    batch_size=2,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_net(checkpoint_path):\n    config = get_efficientdet_config('tf_efficientdet_d5')\n    net = EfficientDet(config, pretrained_backbone=False)\n\n    config.num_classes = 21\n    config.image_size=512\n    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n\n    del checkpoint\n    gc.collect()\n\n    net = DetBenchEval(net, config)\n    net.eval();\n    return net.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = load_net('../input/dai-ck1/best-checkpoint-018epoch.bin')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trial"},{"metadata":{"trusted":true},"cell_type":"code","source":"image , ids = next(iter(data_loader)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = torch.stack(image).cuda().float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    det = net(images , torch.tensor([1]*images.shape[0]).float().cuda())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes = det[i].detach().cpu().numpy()[:,:4]    \nscores = det[i].detach().cpu().numpy()[:,4]\nlabels = det[i].detach().cpu().numpy()[:,5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = np.where(scores > .10)[0]\nboxes = boxes[indexes]\nboxes[:, 2] = boxes[:, 2] + boxes[:, 0]\nboxes[:, 3] = boxes[:, 3] + boxes[:, 1]\npredictions.append({\n    'boxes': boxes[indexes],\n    'scores': scores[indexes],\n    'labels':labels[indexes]\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Prediction Function and WBF"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(images, score_threshold=0.22):\n    images = torch.stack(images).cuda().float()\n    predictions = []\n    with torch.no_grad():\n        det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n        for i in range(images.shape[0]):\n            boxes = det[i].detach().cpu().numpy()[:,:4]    \n            scores = det[i].detach().cpu().numpy()[:,4]\n            labels = det[i].detach().cpu().numpy()[:,5]\n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n            predictions.append({\n                'boxes': boxes[indexes],\n                'scores': scores[indexes],\n                'labels':labels[indexes]\n            })\n    return [predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_wbf(predictions, image_index, image_size=512, iou_thr=0.5, skip_box_thr=0.12, weights=None):\n    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n    labels = [prediction[image_index]['labels'].tolist() for prediction in predictions]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trial Again"},{"metadata":{"trusted":true},"cell_type":"code","source":"image , ids = next(iter(data_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = make_predictions(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nsample = image[i].permute(1,2,0).cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes , scores , labels = run_wbf(predictions,image_index=i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes = boxes.astype(np.int32).clip(min=0,max=511)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,1,figsize=(20,8))\nfor i,box in enumerate(boxes):\n    cv2.rectangle(sample,(box[0],box[1]),(box[2],box[3]),(1,0,0),2)\n    cv2.putText(sample,le.inverse_transform([int(labels[i])])[0] , (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 1)\n    \nax.set_axis_off()\nax.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trial for Convert Aug"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_transform = get_convert_transforms()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial = conv_transform(image=np.float32(image[0].permute(1,2,0)),bboxes=boxes,labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = trial['image']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial['bboxes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox = (torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,1,figsize=(20,8))\nfor i,box in enumerate(bbox):\n    cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(1,0,0),2)\n    #cv2.putText(sample,le.inverse_transform([int(labels[i])])[0] , (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 1)\n    \nax.set_axis_off()\nax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Complete Pipeline to Get Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"image , ids = next(iter(data_loader))\npredictions = make_predictions(image)\n\ni=0\n\nsample = image[i].permute(1,2,0).cpu().numpy()\n\nboxes , scores , labels = run_wbf(predictions,image_index=i)\nboxes = boxes.astype(np.int32).clip(min=0,max=511)\n\ntrial = conv_transform(image=sample,bboxes=boxes,labels=labels)\n\nimg = trial['image']\n\nbbox = np.int32((torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,1,figsize=(20,8))\nfor i,box in enumerate(bbox):\n    cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(1,0,0),2)\n    cv2.putText(img,le.inverse_transform([int(labels[i])])[0] , (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n    \nax.set_axis_off()\nax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Submission.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_try = {'image_id':[],'class':[],'score':[],'xmin':[],'ymin':[],'xmax':[],'ymax':[]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try = pd.DataFrame.from_dict(dict_try)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image , im_id = next(iter(data_loader))\nim_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = make_predictions(image)\n\ni=0\n\nsample = image[i].permute(1,2,0).cpu().numpy()\n\nboxes , scores , labels = run_wbf(predictions,image_index=i)\nboxes = boxes.astype(np.int32).clip(min=0,max=511)\n\ntrial = conv_transform(image=sample,bboxes=boxes,labels=labels)\n\nimg = trial['image']\n\nbbox = np.int32((torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[0][0]['scores']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.inverse_transform([int(labels[0])])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,box in enumerate(bbox):\n    dict_1 = {'image_id':[f\"{im_id[0]}.jpg\"] ,'class':le.inverse_transform([int(labels[i])])[0] , \n              'score' : predictions[0][0]['scores'][i],\n             'xmin':box[0] , 'ymin':box[1] , 'xmax':box[2] , 'ymax':box[3]}\n    df_1 = pd.DataFrame.from_dict(dict_1)\n    df_try = pd.concat([df_try,df_1],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Final Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_try = {'image_id':[],'class':[],'score':[],'xmin':[],'ymin':[],'xmax':[],'ymax':[]}\ndf_try = pd.DataFrame.from_dict(dict_try)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image,im_id in data_loader:\n    predictions = make_predictions(image)\n    for k in range(len(image)):\n        sample = image[k].permute(1,2,0).cpu().numpy()\n\n        boxes , scores , labels = run_wbf(predictions,image_index=k)\n        boxes = boxes.astype(np.int32).clip(min=0,max=511)\n\n        trial = conv_transform(image=sample,bboxes=boxes,labels=labels)\n\n        img = trial['image']\n        \n        try:\n            bbox = np.int32((torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy())\n        except:\n            continue\n        \n        for i,box in enumerate(bbox):\n            dict_1 = {'image_id':[f\"{im_id[k]}.jpg\"] ,'class':le.inverse_transform([int(labels[i])])[0] , \n                      'score' : predictions[0][k]['scores'][i],\n                     'xmin':box[0] , 'ymin':box[1] , 'xmax':box[2] , 'ymax':box[3]}\n            df_1 = pd.DataFrame.from_dict(dict_1)\n            df_try = pd.concat([df_try,df_1],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Fixing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try.loc[:,'width'] = 1024\ndf_try.loc[:,'height'] = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try.to_csv('submit1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_wbf(predictions, image_index, image_size=512, iou_thr=0.50, skip_box_thr=0.30, weights=None):\n    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n    labels = [prediction[image_index]['labels'].tolist() for prediction in predictions]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size-1)\n    return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = np.random.randint(len(data_loader))\nfor j,(image,im_id) in enumerate(data_loader):\n    if (j==k):\n        predictions = make_predictions(image)\n\n        i=1\n\n        sample = image[i].permute(1,2,0).cpu().numpy()\n\n        boxes , scores , labels = run_wbf(predictions,image_index=i)\n        boxes = boxes.astype(np.int32).clip(min=0,max=511)\n\n        trial = conv_transform(image=sample,bboxes=boxes,labels=labels)\n\n        img = trial['image']\n\n        bbox = np.int32((torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy())\n        \n        \n        for i,box in enumerate(bbox):\n            cv2.rectangle(img,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(1,0,0),2)\n            cv2.putText(img,le.inverse_transform([int(labels[i])])[0] , (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,1,0), 2)\n            \n        break\n        \nfig , ax = plt.subplots(1,1,figsize=(20,8))\n\nax.set_axis_off()\nax.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Another submission for IOU Threshold change"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_try = {'image_id':[],'class':[],'score':[],'xmin':[],'ymin':[],'xmax':[],'ymax':[]}\ndf_try = pd.DataFrame.from_dict(dict_try)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image,im_id in data_loader:\n    predictions = make_predictions(image)\n    for k in range(len(image)):\n        sample = image[k].permute(1,2,0).cpu().numpy()\n\n        boxes , scores , labels = run_wbf(predictions,image_index=k)\n        boxes = boxes.astype(np.int32).clip(min=0,max=511)\n\n        trial = conv_transform(image=sample,bboxes=boxes,labels=labels)\n\n        img = trial['image']\n        \n        try:\n            bbox = np.int32((torch.stack(tuple(map(torch.tensor, zip(*trial['bboxes'])))).permute(1, 0)).numpy())\n        except:\n            continue\n        \n        for i,box in enumerate(bbox):\n            dict_1 = {'image_id':[f\"{im_id[k]}.jpg\"] ,'class':le.inverse_transform([int(labels[i])])[0] , \n                      'score' : predictions[0][k]['scores'][i],\n                     'xmin':box[0] , 'ymin':box[1] , 'xmax':box[2] , 'ymax':box[3]}\n            df_1 = pd.DataFrame.from_dict(dict_1)\n            df_try = pd.concat([df_try,df_1],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try.loc[:,'width'] = 1024\ndf_try.loc[:,'height'] = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_try.to_csv('submit1_2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}